{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb3c7c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "os.chdir('/home/jcsanguino10/local_citation_model/recommender-fusion-recsys/loaders')\n",
    "from create_dataloader_sequential import (load_course_encoder)\n",
    "\n",
    "os.chdir('/home/jcsanguino10/local_citation_model/recommender-fusion-recsys/architectures/Sequence')\n",
    "from sec_transformer_pytorch import (create_model, load_pytorch_weights)\n",
    "\n",
    "os.chdir('/home/jcsanguino10/local_citation_model/recommender-fusion-recsys/architectures/Multimodal')\n",
    "from multimodal import Autoencoder, MultimodalModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caddf8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # Change to just a particular GPU changing the enviroment variable\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "    device = torch.device(\"cuda\")\n",
    "    # Change to just use a particular GPU via torch\n",
    "    #torch.cuda.set_device(\"cuda:3\")\n",
    "    print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c9edd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths from the label encoder dicts \n",
    "\n",
    "PATH_TO_LABEL_ENCODER = '/home/jcsanguino10/local_citation_model/data/processed/'\n",
    "\n",
    "# Path to folder with datasets\n",
    "\n",
    "PATH_TO_DATASETS = '/home/jcsanguino10/local_citation_model/data/'\n",
    "\n",
    "# Path to folder with checkpoints best models\n",
    "\n",
    "PATH_TO_CHECKPOINTS = '/home/jcsanguino10/local_citation_model/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44862572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing mappings from /home/jcsanguino10/local_citation_model/data/processed\n"
     ]
    }
   ],
   "source": [
    "label_encoder, dicts = load_course_encoder('/home', PATH_TO_LABEL_ENCODER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da2c5f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_encoder.classes_)  # List of all course IDs in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "177798f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_binary = pd.read_pickle(f'{PATH_TO_DATASETS}train_binary_all_vectors_128_01_transe_seqvec.pkl')\n",
    "df_bpr_df = pd.read_pickle(f'{PATH_TO_DATASETS}train_bpr_all_vectors_128_01_transe_seqvec.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aa3b521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_columns_to_tensor(df, columns, new_column_name):\n",
    "    \"\"\"\n",
    "    Concatenates specified columns in a DataFrame and creates a tensor.\n",
    "    The resulting tensor is saved in a new column.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        columns (list): List of column names to concatenate.\n",
    "        new_column_name (str): Name of the new column to store the tensor.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with the new column containing tensors.\n",
    "    \"\"\"\n",
    "    df[new_column_name] = df[columns].apply(\n",
    "        lambda row: torch.tensor([item for col in columns for item in row[col]], dtype=torch.float),\n",
    "        axis=1\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b183f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_binary = concat_columns_to_tensor(df_binary, ['item_bpr_embedding'], 'course_full_embeddings')\n",
    "df_binary = concat_columns_to_tensor(df_binary, ['user_bpr_embedding'], 'user_full_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d9d51ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bpr_df = concat_columns_to_tensor(df_bpr_df, ['pos_item_bpr_embedding'], 'pos_course_full_embeddings')\n",
    "df_bpr_df = concat_columns_to_tensor(df_bpr_df, ['neg_item_bpr_embedding'], 'neg_course_full_embeddings')\n",
    "df_bpr_df = concat_columns_to_tensor(df_bpr_df, ['user_bpr_embedding'], 'user_full_embeddings')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092eee90",
   "metadata": {},
   "source": [
    "# Autoencoder training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dcd662f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder_and_extract_encoder(data, input_dim, encoding_dims, epochs=50, lr=1e-3, \n",
    "                                         save_path=None, device='cuda', verbose=True):\n",
    "    \"\"\"\n",
    "    Train an autoencoder.\n",
    "    \n",
    "    Args:\n",
    "        data (torch.Tensor): Training data tensor of shape (batch_size, input_dim)\n",
    "        input_dim (int): Dimension of input features\n",
    "        encoding_dims (list): List of hidden layer dimensions for encoder\n",
    "                             Example: [512, 256, 128] for 3-layer encoder\n",
    "        epochs (int): Number of training epochs\n",
    "        lr (float): Learning rate\n",
    "        save_path (str): Path to save the best autoencoder model (optional)\n",
    "        device (str): Device to train on ('cpu' or 'cuda')\n",
    "        verbose (bool): Whether to print training progress\n",
    "        \n",
    "    Returns:\n",
    "        encoder (nn.Module): The trained autoencoder model\n",
    "    \"\"\"\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Starting autoencoder training...\")\n",
    "        print(f\"Input dimension: {input_dim}\")\n",
    "        print(f\"Encoding dimensions: {encoding_dims}\")\n",
    "        print(f\"Final encoding dimension: {encoding_dims[-1]}\")\n",
    "        print(f\"Training data shape: {data.shape}\")\n",
    "    \n",
    "    # Create autoencoder\n",
    "    autoencoder = Autoencoder(input_dim=input_dim, encoding_dims=encoding_dims)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Autoencoder architecture created\")\n",
    "        print(f\"Encoder layers: {len(autoencoder.encoder)}\")\n",
    "        print(f\"Decoder layers: {len(autoencoder.decoder)}\")\n",
    "    \n",
    "    # Train the autoencoder using the enhanced train_autoencoder method\n",
    "    trained_autoencoder = Autoencoder.train_autoencoder(\n",
    "        autoencoder=autoencoder,\n",
    "        data=data,\n",
    "        epochs=epochs,\n",
    "        lr=lr,\n",
    "        save_path=save_path,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Training completed!\")\n",
    "        print(f\"Encoder extracted successfully\")\n",
    "        print(f\"Encoder output dimension: {encoding_dims[-1]}\")\n",
    "    \n",
    "    return trained_autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6c383b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3863658/2275731313.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  course_tensor = [torch.tensor(x, dtype=torch.float) for x in df_binary['course_full_embeddings'].values]\n",
      "/tmp/ipykernel_3863658/2275731313.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  user_tensor = [torch.tensor(x, dtype=torch.float) for x in df_binary['user_full_embeddings'].values]\n"
     ]
    }
   ],
   "source": [
    "course_tensor = [torch.tensor(x, dtype=torch.float) for x in df_binary['course_full_embeddings'].values]\n",
    "embeddings__course_tensor = torch.stack(course_tensor)\n",
    "\n",
    "user_tensor = [torch.tensor(x, dtype=torch.float) for x in df_binary['user_full_embeddings'].values]\n",
    "embeddings_user_tensor = torch.stack(user_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9abd9a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#course_encoder = train_autoencoder_and_extract_encoder(embeddings__course_tensor, embeddings__course_tensor.shape[1], [720, 562, 432], save_path=f'{PATH_TO_CHECKPOINTS}encoder_course.pth' ,epochs=100, lr=1e-3, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31f816a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_encoder = train_autoencoder_and_extract_encoder(embeddings_user_tensor, embeddings_user_tensor.shape[1], [720, 562, 432], save_path=f'{PATH_TO_CHECKPOINTS}encoder_user.pth' ,epochs=100, lr=1e-3, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b415eb1",
   "metadata": {},
   "source": [
    "# Multimodal training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c65457c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "modality_dims = {\n",
    "    'course': embeddings__course_tensor.shape[1],\n",
    "    'user': embeddings_user_tensor.shape[1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5519a170",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_encoder = MultimodalModel(modality_dims, use_bpr=True, fusion_method='by_autoencoder',shared_dim=64, layers_per_modality=[312 ,256, 128] ,autoencoders={'course': course_encoder, 'user': user_encoder}, autoencoder_output_dim=432)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af23d28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataloader for BPR training using the df_bpr_df dataframe with the columns: pos_course_full_embeddings, neg_course_full_embeddings, user_full_embeddings\n",
    "class BPRDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user_feat = self.df.iloc[idx]['user_full_embeddings']\n",
    "        pos_course_feat = self.df.iloc[idx]['pos_course_full_embeddings']\n",
    "        neg_course_feat = self.df.iloc[idx]['neg_course_full_embeddings']\n",
    "        return {\n",
    "            'user': torch.tensor(user_feat, dtype=torch.float),\n",
    "            'course_positive': torch.tensor(pos_course_feat, dtype=torch.float),\n",
    "            'course_negative': torch.tensor(neg_course_feat, dtype=torch.float)\n",
    "        }\n",
    "bpr_dataset = BPRDataset(df_bpr_df)\n",
    "bpr_dataloader = torch.utils.data.DataLoader(bpr_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79d1e1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_encoder.train_model(\n",
    "#     train_loader=bpr_dataloader,\n",
    "#     epochs=50,\n",
    "#     lr=1e-3,\n",
    "#     device='cuda',\n",
    "#     save_path=f'{PATH_TO_CHECKPOINTS}multimodal_encoder_bpr_model.pth'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91c5277d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User feature layer input dim: 128\n",
      "Course feature layer input dim: 128\n"
     ]
    }
   ],
   "source": [
    "model_no_encoder = MultimodalModel(modality_dims, use_bpr=True, fusion_method='concat',shared_dim=128, layers_per_modality=[128] ,autoencoders=None, autoencoder_output_dim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30d64382",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3863658/242066864.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'user': torch.tensor(user_feat, dtype=torch.float),\n",
      "/tmp/ipykernel_3863658/242066864.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'course_positive': torch.tensor(pos_course_feat, dtype=torch.float),\n",
      "/tmp/ipykernel_3863658/242066864.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'course_negative': torch.tensor(neg_course_feat, dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "model_no_encoder.train_model(\n",
    "    train_loader=bpr_dataloader,\n",
    "    epochs=30,\n",
    "    lr=1e-3,\n",
    "    device='cuda',\n",
    "    save_path=f'{PATH_TO_CHECKPOINTS}multimodal_no_encoder_bpr_model.pth',\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92a17f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create dataloaders for binary training using the df_binary dataframe with the columns: course_full_embeddings, user_full_embeddings\n",
    "class BinaryDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user_feat = self.df.iloc[idx]['user_full_embeddings']\n",
    "        course_feat = self.df.iloc[idx]['course_full_embeddings']\n",
    "        label = self.df.iloc[idx]['label']\n",
    "        return {\n",
    "            'user': torch.tensor(user_feat, dtype=torch.float),\n",
    "            'course_positive': torch.tensor(course_feat, dtype=torch.float),\n",
    "            'targets': torch.tensor(label, dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ce7ed61",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split df_binary into train and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, val_df = train_test_split(df_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "binary_dataset = BinaryDataset(train_df)\n",
    "binary_dataloader = torch.utils.data.DataLoader(binary_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "val_dataset = BinaryDataset(val_df)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0dbe02ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_binary = MultimodalModel(modality_dims, use_bpr=True, fusion_method='by_autoencoder',shared_dim=64, layers_per_modality=[312 ,256, 128] ,autoencoders={'course': course_encoder, 'user': user_encoder}, autoencoder_output_dim=432)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d3b11c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User feature layer input dim: 128\n",
      "Course feature layer input dim: 128\n"
     ]
    }
   ],
   "source": [
    "model_binary_no_encoder = MultimodalModel(modality_dims, use_bpr=False, fusion_method='concat',shared_dim=128, layers_per_modality=[128] ,autoencoders=None, autoencoder_output_dim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "588a0a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_binary.train_model(\n",
    "#     train_loader=binary_dataloader,\n",
    "#     val_loader=val_dataloader,\n",
    "#     epochs=50,\n",
    "#     lr=1e-3,\n",
    "#     device='cuda',\n",
    "#     save_path=f'{PATH_TO_CHECKPOINTS}multimodal_encoder_binary_model.pth'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93e0ce64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3863658/754840888.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'user': torch.tensor(user_feat, dtype=torch.float),\n",
      "/tmp/ipykernel_3863658/754840888.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'course_positive': torch.tensor(course_feat, dtype=torch.float),\n"
     ]
    }
   ],
   "source": [
    "model_binary_no_encoder.train_model(\n",
    "    train_loader=binary_dataloader,\n",
    "    val_loader=val_dataloader,\n",
    "    epochs=30,\n",
    "    lr=1e-3,\n",
    "    device='cuda',\n",
    "    save_path=f'{PATH_TO_CHECKPOINTS}multimodal_no_encoder_binary_model.pth',\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6dd47b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_test_binary = pd.read_pickle(f'{PATH_TO_DATASETS}test_binary_all_vectors_128_01_transe_seqvec.pkl')\n",
    "df_test_bpr = pd.read_pickle(f'{PATH_TO_DATASETS}test_bpr_all_vectors_128_01_transe_seqvec.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5c3820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df_train = df_binary.drop_duplicates(subset=['user_id']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7fcecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a mapping of all user IDs to the list of course IDs they have taken using the full_item_seq column in df_bpr_df\n",
    "user_courses_taken = {}\n",
    "for _, row in temp_df_train.iterrows():\n",
    "    user_id = row['user_id']\n",
    "    courses = row['full_item_seq']\n",
    "    user_courses_taken[user_id] = courses\n",
    "\n",
    "#Create a mapping of all user IDs and the user embeddings\n",
    "user_embedding_mapping = {}\n",
    "for _, row in temp_df_train.iterrows():\n",
    "    user_id = row['user_id']\n",
    "    embedding = row['user_full_embeddings']\n",
    "    user_embedding_mapping[user_id] = embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bea5514e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df_test = df_test_binary.drop_duplicates(subset=['user_id']).reset_index(drop=True)[['user_id', 'full_item_seq']]\n",
    "\n",
    "#Create a new column in temp_df_test with the list of courses already taken by each user\n",
    "temp_df_test['courses_taken'] = temp_df_test['user_id'].map(user_courses_taken)\n",
    "temp_df_test['user_full_embeddings'] = temp_df_test['user_id'].map(user_embedding_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48ae8428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>full_item_seq</th>\n",
       "      <th>courses_taken</th>\n",
       "      <th>user_full_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[6897]</td>\n",
       "      <td>[6863, 6864]</td>\n",
       "      <td>[tensor(-0.1649), tensor(0.1331), tensor(-0.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[6920]</td>\n",
       "      <td>[6865, 6866]</td>\n",
       "      <td>[tensor(-0.1568), tensor(0.1479), tensor(-0.14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[6937, 6961, 6895, 6950, 6964, 6965, 6994, 702...</td>\n",
       "      <td>[6867, 6868, 6869, 6870, 6871, 6872, 6873, 687...</td>\n",
       "      <td>[tensor(-0.1206), tensor(0.1338), tensor(-0.13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[6996]</td>\n",
       "      <td>[6870, 6872]</td>\n",
       "      <td>[tensor(-0.1470), tensor(0.1081), tensor(-0.11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[6901, 6865, 6912]</td>\n",
       "      <td>[6894, 6895, 6872, 6870]</td>\n",
       "      <td>[tensor(-0.1137), tensor(0.1420), tensor(-0.11...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                      full_item_seq  \\\n",
       "0        0                                             [6897]   \n",
       "1        1                                             [6920]   \n",
       "2        2  [6937, 6961, 6895, 6950, 6964, 6965, 6994, 702...   \n",
       "3        3                                             [6996]   \n",
       "4        4                                 [6901, 6865, 6912]   \n",
       "\n",
       "                                       courses_taken  \\\n",
       "0                                       [6863, 6864]   \n",
       "1                                       [6865, 6866]   \n",
       "2  [6867, 6868, 6869, 6870, 6871, 6872, 6873, 687...   \n",
       "3                                       [6870, 6872]   \n",
       "4                           [6894, 6895, 6872, 6870]   \n",
       "\n",
       "                                user_full_embeddings  \n",
       "0  [tensor(-0.1649), tensor(0.1331), tensor(-0.10...  \n",
       "1  [tensor(-0.1568), tensor(0.1479), tensor(-0.14...  \n",
       "2  [tensor(-0.1206), tensor(0.1338), tensor(-0.13...  \n",
       "3  [tensor(-0.1470), tensor(0.1081), tensor(-0.11...  \n",
       "4  [tensor(-0.1137), tensor(0.1420), tensor(-0.11...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd88b492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a mapping of all course IDs to their course_full_embeddings\n",
    "course_sequence_mapping = {}\n",
    "for _, row in df_binary.drop_duplicates(subset=['item_id']).iterrows():\n",
    "    item_id = row['item_id']\n",
    "    course = row['course_full_embeddings']\n",
    "    course_sequence_mapping[item_id] = course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8072d1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/jcsanguino10/local_citation_model/Secuencial SR')\n",
    "from evaluation_metrics import calculate_average_mrr, calculate_average_precision_at_k, calculate_average_ndcg_at_k, calculate_average_custom_precision_at_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9205b4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendations_per_user(df, model, courses_dict, k=5, batch_size=64):\n",
    "\n",
    "    user_tensors = [torch.tensor(x) if not isinstance(x, torch.Tensor) else x \n",
    "                for x in df[\"user_full_embeddings\"].values]\n",
    "\n",
    "    user_tensors = torch.stack(user_tensors)\n",
    "\n",
    "    all_user_embs = user_tensors  # shape [num_users, dim]\n",
    "\n",
    "    courses_already_taken = df[\"courses_taken\"].values\n",
    "    recommendations = []\n",
    "\n",
    "    for i in tqdm(range(0, len(all_user_embs), batch_size), desc=\"Generating recommendations\"):\n",
    "        batch = all_user_embs[i:i+batch_size]\n",
    "        batch_courses_taken = courses_already_taken[i:i+batch_size]\n",
    "        # Generate recommendations for the batch\n",
    "        batch_recs = model.generate_k_recommendations(courses_dict, batch, batch_courses_taken, k=k)\n",
    "        recommendations.extend(batch_recs)\n",
    "\n",
    "    df[\"recommendations\"] = recommendations\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b63a49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(df, models, courses_dict, k):\n",
    "    for model in models:\n",
    "        temp_df = generate_recommendations_per_user(df.drop_duplicates(subset=\"user_id\"), model, courses_dict)\n",
    "        k=5\n",
    "        courses_test_dataset = temp_df[\"full_item_seq\"].to_list()\n",
    "        courses_recommended_list = temp_df[\"recommendations\"].to_list()\n",
    "\n",
    "        avg_mrr = calculate_average_mrr(courses_test_dataset, courses_recommended_list)\n",
    "        avg_ndcg_at_k = calculate_average_ndcg_at_k(courses_test_dataset, courses_recommended_list, k)\n",
    "        avg_precision_at_k = calculate_average_precision_at_k(courses_test_dataset, courses_recommended_list, k)\n",
    "        avg_custom_precision_at_k = calculate_average_custom_precision_at_k(courses_test_dataset, courses_recommended_list, k)\n",
    "        print(f\"Average MRR: {avg_mrr}\")\n",
    "        print(f\"Average NDCG@{k}: {avg_ndcg_at_k}\")\n",
    "        print(f\"Average Precision@{k}: {avg_precision_at_k}\")\n",
    "        print(f\"Average Custom Precision@{k}: {avg_custom_precision_at_k}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f619832",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating recommendations: 100%|██████████| 108/108 [00:00<00:00, 235.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MRR: 0.1751153528583239\n",
      "Average NDCG@5: 0.2395144053322115\n",
      "Average Precision@5: 0.08917383068628834\n",
      "Average Custom Precision@5: 0.2731118558453542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating recommendations: 100%|██████████| 108/108 [00:04<00:00, 26.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MRR: 0.16040604206129672\n",
      "Average NDCG@5: 0.21544790706181466\n",
      "Average Precision@5: 0.07777939676526072\n",
      "Average Custom Precision@5: 0.24131575112924358\n"
     ]
    }
   ],
   "source": [
    "# test_model(temp_df_test, models=[model_no_encoder, model_binary_no_encoder], courses_dict=course_sequence_mapping, k=5)\n",
    "test_model(temp_df_test, models=[model_no_encoder, model_binary_no_encoder], courses_dict=course_sequence_mapping, k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local_citation_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
