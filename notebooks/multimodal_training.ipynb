{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a00c80d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Loading existing mappings from /home/jcsanguino10/local_citation_model/data/processed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir('/home/jcsanguino10/local_citation_model/recommender-fusion-recsys/notebooks')\n",
    "import multimodal_training as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d252b8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['item_bpr_embedding'], ['user_bpr_embedding'])\n",
      "(['item_graph_embedding'], ['user_graph_embedding'])\n",
      "(['item_text_embedding'], ['user_text_embedding'])\n",
      "(['item_bpr_embedding', 'item_graph_embedding'], ['user_bpr_embedding', 'user_graph_embedding'])\n",
      "(['item_bpr_embedding', 'item_text_embedding'], ['user_bpr_embedding', 'user_text_embedding'])\n",
      "(['item_graph_embedding', 'item_text_embedding'], ['user_graph_embedding', 'user_text_embedding'])\n",
      "(['item_bpr_embedding', 'item_graph_embedding', 'item_text_embedding'], ['user_bpr_embedding', 'user_graph_embedding', 'user_text_embedding'])\n",
      "(['item_bpr_embedding'], ['user_bpr_embedding', 'user_sequence_embedding'])\n",
      "(['item_graph_embedding'], ['user_graph_embedding', 'user_sequence_embedding'])\n",
      "(['item_text_embedding'], ['user_text_embedding', 'user_sequence_embedding'])\n",
      "(['item_bpr_embedding', 'item_graph_embedding'], ['user_bpr_embedding', 'user_graph_embedding', 'user_sequence_embedding'])\n",
      "(['item_bpr_embedding', 'item_text_embedding'], ['user_bpr_embedding', 'user_text_embedding', 'user_sequence_embedding'])\n",
      "(['item_graph_embedding', 'item_text_embedding'], ['user_graph_embedding', 'user_text_embedding', 'user_sequence_embedding'])\n",
      "(['item_bpr_embedding', 'item_graph_embedding', 'item_text_embedding'], ['user_bpr_embedding', 'user_graph_embedding', 'user_text_embedding', 'user_sequence_embedding'])\n",
      "Total de combinaciones: 14\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain, combinations\n",
    "\n",
    "modalities = {\n",
    "    'bpr': ('item_bpr_embedding', 'user_bpr_embedding'),\n",
    "    'graph': ('item_graph_embedding', 'user_graph_embedding'),\n",
    "    'text': ('item_text_embedding', 'user_text_embedding'),\n",
    "}\n",
    "\n",
    "sequence = 'user_sequence_embedding'  # Solo usuario\n",
    "\n",
    "def powerset(iterable):\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(1, len(s)+1))\n",
    "\n",
    "final_combinations = []\n",
    "\n",
    "for combo in powerset(modalities.keys()):\n",
    "    item_embeds = [modalities[m][0] for m in combo]\n",
    "    user_embeds = [modalities[m][1] for m in combo]\n",
    "    final_combinations.append((item_embeds, user_embeds))\n",
    "\n",
    "with_sequence = [ (items, users + [sequence]) for (items, users) in final_combinations ]\n",
    "final_combinations.extend(with_sequence)\n",
    "\n",
    "\n",
    "# Mostrar resultados\n",
    "for combo in final_combinations:\n",
    "    print(combo)\n",
    "\n",
    "print(\"Total de combinaciones:\", len(final_combinations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "630591d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('item_bpr_embedding',),\n",
       " ('user_bpr_embedding',),\n",
       " ('item_graph_embedding',),\n",
       " ('user_graph_embedding',),\n",
       " ('item_text_embedding',),\n",
       " ('user_text_embedding',),\n",
       " ('item_bpr_embedding', 'user_bpr_embedding'),\n",
       " ('item_bpr_embedding', 'item_graph_embedding'),\n",
       " ('item_bpr_embedding', 'user_graph_embedding'),\n",
       " ('item_bpr_embedding', 'item_text_embedding'),\n",
       " ('item_bpr_embedding', 'user_text_embedding'),\n",
       " ('user_bpr_embedding', 'item_graph_embedding'),\n",
       " ('user_bpr_embedding', 'user_graph_embedding'),\n",
       " ('user_bpr_embedding', 'item_text_embedding'),\n",
       " ('user_bpr_embedding', 'user_text_embedding'),\n",
       " ('item_graph_embedding', 'user_graph_embedding'),\n",
       " ('item_graph_embedding', 'item_text_embedding'),\n",
       " ('item_graph_embedding', 'user_text_embedding'),\n",
       " ('user_graph_embedding', 'item_text_embedding'),\n",
       " ('user_graph_embedding', 'user_text_embedding'),\n",
       " ('item_text_embedding', 'user_text_embedding'),\n",
       " ('item_bpr_embedding', 'user_bpr_embedding', 'item_graph_embedding'),\n",
       " ('item_bpr_embedding', 'user_bpr_embedding', 'user_graph_embedding'),\n",
       " ('item_bpr_embedding', 'user_bpr_embedding', 'item_text_embedding'),\n",
       " ('item_bpr_embedding', 'user_bpr_embedding', 'user_text_embedding'),\n",
       " ('item_bpr_embedding', 'item_graph_embedding', 'user_graph_embedding'),\n",
       " ('item_bpr_embedding', 'item_graph_embedding', 'item_text_embedding'),\n",
       " ('item_bpr_embedding', 'item_graph_embedding', 'user_text_embedding'),\n",
       " ('item_bpr_embedding', 'user_graph_embedding', 'item_text_embedding'),\n",
       " ('item_bpr_embedding', 'user_graph_embedding', 'user_text_embedding'),\n",
       " ('item_bpr_embedding', 'item_text_embedding', 'user_text_embedding'),\n",
       " ('user_bpr_embedding', 'item_graph_embedding', 'user_graph_embedding'),\n",
       " ('user_bpr_embedding', 'item_graph_embedding', 'item_text_embedding'),\n",
       " ('user_bpr_embedding', 'item_graph_embedding', 'user_text_embedding'),\n",
       " ('user_bpr_embedding', 'user_graph_embedding', 'item_text_embedding'),\n",
       " ('user_bpr_embedding', 'user_graph_embedding', 'user_text_embedding'),\n",
       " ('user_bpr_embedding', 'item_text_embedding', 'user_text_embedding'),\n",
       " ('item_graph_embedding', 'user_graph_embedding', 'item_text_embedding'),\n",
       " ('item_graph_embedding', 'user_graph_embedding', 'user_text_embedding'),\n",
       " ('item_graph_embedding', 'item_text_embedding', 'user_text_embedding'),\n",
       " ('user_graph_embedding', 'item_text_embedding', 'user_text_embedding'),\n",
       " ('item_bpr_embedding',\n",
       "  'user_bpr_embedding',\n",
       "  'item_graph_embedding',\n",
       "  'user_graph_embedding'),\n",
       " ('item_bpr_embedding',\n",
       "  'user_bpr_embedding',\n",
       "  'item_graph_embedding',\n",
       "  'item_text_embedding'),\n",
       " ('item_bpr_embedding',\n",
       "  'user_bpr_embedding',\n",
       "  'item_graph_embedding',\n",
       "  'user_text_embedding'),\n",
       " ('item_bpr_embedding',\n",
       "  'user_bpr_embedding',\n",
       "  'user_graph_embedding',\n",
       "  'item_text_embedding'),\n",
       " ('item_bpr_embedding',\n",
       "  'user_bpr_embedding',\n",
       "  'user_graph_embedding',\n",
       "  'user_text_embedding'),\n",
       " ('item_bpr_embedding',\n",
       "  'user_bpr_embedding',\n",
       "  'item_text_embedding',\n",
       "  'user_text_embedding'),\n",
       " ('item_bpr_embedding',\n",
       "  'item_graph_embedding',\n",
       "  'user_graph_embedding',\n",
       "  'item_text_embedding'),\n",
       " ('item_bpr_embedding',\n",
       "  'item_graph_embedding',\n",
       "  'user_graph_embedding',\n",
       "  'user_text_embedding'),\n",
       " ('item_bpr_embedding',\n",
       "  'item_graph_embedding',\n",
       "  'item_text_embedding',\n",
       "  'user_text_embedding'),\n",
       " ('item_bpr_embedding',\n",
       "  'user_graph_embedding',\n",
       "  'item_text_embedding',\n",
       "  'user_text_embedding'),\n",
       " ('user_bpr_embedding',\n",
       "  'item_graph_embedding',\n",
       "  'user_graph_embedding',\n",
       "  'item_text_embedding'),\n",
       " ('user_bpr_embedding',\n",
       "  'item_graph_embedding',\n",
       "  'user_graph_embedding',\n",
       "  'user_text_embedding'),\n",
       " ('user_bpr_embedding',\n",
       "  'item_graph_embedding',\n",
       "  'item_text_embedding',\n",
       "  'user_text_embedding'),\n",
       " ('user_bpr_embedding',\n",
       "  'user_graph_embedding',\n",
       "  'item_text_embedding',\n",
       "  'user_text_embedding'),\n",
       " ('item_graph_embedding',\n",
       "  'user_graph_embedding',\n",
       "  'item_text_embedding',\n",
       "  'user_text_embedding'),\n",
       " ('item_bpr_embedding',\n",
       "  'user_bpr_embedding',\n",
       "  'item_graph_embedding',\n",
       "  'user_graph_embedding',\n",
       "  'item_text_embedding'),\n",
       " ('item_bpr_embedding',\n",
       "  'user_bpr_embedding',\n",
       "  'item_graph_embedding',\n",
       "  'user_graph_embedding',\n",
       "  'user_text_embedding'),\n",
       " ('item_bpr_embedding',\n",
       "  'user_bpr_embedding',\n",
       "  'item_graph_embedding',\n",
       "  'item_text_embedding',\n",
       "  'user_text_embedding'),\n",
       " ('item_bpr_embedding',\n",
       "  'user_bpr_embedding',\n",
       "  'user_graph_embedding',\n",
       "  'item_text_embedding',\n",
       "  'user_text_embedding'),\n",
       " ('item_bpr_embedding',\n",
       "  'item_graph_embedding',\n",
       "  'user_graph_embedding',\n",
       "  'item_text_embedding',\n",
       "  'user_text_embedding'),\n",
       " ('user_bpr_embedding',\n",
       "  'item_graph_embedding',\n",
       "  'user_graph_embedding',\n",
       "  'item_text_embedding',\n",
       "  'user_text_embedding'),\n",
       " ('item_bpr_embedding',\n",
       "  'user_bpr_embedding',\n",
       "  'item_graph_embedding',\n",
       "  'user_graph_embedding',\n",
       "  'item_text_embedding',\n",
       "  'user_text_embedding')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "course_column_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b3b9d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATASETS = '/home/jcsanguino10/local_citation_model/data/'\n",
    "\n",
    "df = pd.read_pickle(f'{PATH_TO_DATASETS}train_binary_all_vectors_128_01_transe_seqvec.pkl')\n",
    "df_test = pd.read_pickle(f'{PATH_TO_DATASETS}test_binary_all_vectors_128_01_transe_seqvec.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "860ec329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_seq</th>\n",
       "      <th>item_text_embedding</th>\n",
       "      <th>user_text_embedding</th>\n",
       "      <th>user_cum_text_embedding</th>\n",
       "      <th>item_bpr_embedding</th>\n",
       "      <th>user_bpr_embedding</th>\n",
       "      <th>item_graph_embedding</th>\n",
       "      <th>user_graph_embedding</th>\n",
       "      <th>label</th>\n",
       "      <th>full_item_seq</th>\n",
       "      <th>parsed_item_seq</th>\n",
       "      <th>user_sequence_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6863</td>\n",
       "      <td>[6863]</td>\n",
       "      <td>[2.2087095e-05, 0.01357965, 0.013899612, -0.03...</td>\n",
       "      <td>[-0.022005824, -0.033391304, -0.013403211, -0....</td>\n",
       "      <td>[2.2087095e-05, 0.01357965, 0.013899612, -0.03...</td>\n",
       "      <td>[-0.06554511, 0.082159385, -0.024771133, -0.08...</td>\n",
       "      <td>[-0.16485311, 0.13305487, -0.109800704, -0.159...</td>\n",
       "      <td>[0.027043026, -0.028548103, -0.005808171, -0.1...</td>\n",
       "      <td>[-0.21868221, 0.107340455, 0.20054282, 0.15184...</td>\n",
       "      <td>1</td>\n",
       "      <td>[6863, 6864]</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>[-3.2515903, -4.4112086, 1.4216669, -2.70002, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id item_seq  \\\n",
       "0        0     6863   [6863]   \n",
       "\n",
       "                                 item_text_embedding  \\\n",
       "0  [2.2087095e-05, 0.01357965, 0.013899612, -0.03...   \n",
       "\n",
       "                                 user_text_embedding  \\\n",
       "0  [-0.022005824, -0.033391304, -0.013403211, -0....   \n",
       "\n",
       "                             user_cum_text_embedding  \\\n",
       "0  [2.2087095e-05, 0.01357965, 0.013899612, -0.03...   \n",
       "\n",
       "                                  item_bpr_embedding  \\\n",
       "0  [-0.06554511, 0.082159385, -0.024771133, -0.08...   \n",
       "\n",
       "                                  user_bpr_embedding  \\\n",
       "0  [-0.16485311, 0.13305487, -0.109800704, -0.159...   \n",
       "\n",
       "                                item_graph_embedding  \\\n",
       "0  [0.027043026, -0.028548103, -0.005808171, -0.1...   \n",
       "\n",
       "                                user_graph_embedding  label full_item_seq  \\\n",
       "0  [-0.21868221, 0.107340455, 0.20054282, 0.15184...      1  [6863, 6864]   \n",
       "\n",
       "  parsed_item_seq                            user_sequence_embedding  \n",
       "0          [2, 3]  [-3.2515903, -4.4112086, 1.4216669, -2.70002, ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19b4df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcsanguino10/local_citation_model/recommender-fusion-recsys/notebooks/multimodal_training.py:209: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  course_tensor = [torch.tensor(x, dtype=torch.float) for x in df_binary_temp['course_full_embeddings'].values]\n",
      "/home/jcsanguino10/local_citation_model/recommender-fusion-recsys/notebooks/multimodal_training.py:212: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  user_tensor = [torch.tensor(x, dtype=torch.float) for x in df_binary_temp['user_full_embeddings'].values]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split: 31456 training samples, 7864 validation samples\n",
      "Training autoencoder for 100 epochs...\n",
      " New best model saved at epoch 1 with val_loss: 0.002803\n",
      "Epoch 1/100, Train Loss: 0.003223, Val Loss: 0.002803, Best Val Loss: 0.002803\n",
      " New best model saved at epoch 2 with val_loss: 0.002576\n",
      " New best model saved at epoch 3 with val_loss: 0.002516\n",
      " New best model saved at epoch 4 with val_loss: 0.002445\n",
      " New best model saved at epoch 5 with val_loss: 0.002414\n",
      "Epoch 5/100, Train Loss: 0.002485, Val Loss: 0.002414, Best Val Loss: 0.002414\n",
      " New best model saved at epoch 6 with val_loss: 0.002405\n",
      " New best model saved at epoch 7 with val_loss: 0.002381\n",
      " New best model saved at epoch 8 with val_loss: 0.002332\n",
      " New best model saved at epoch 9 with val_loss: 0.002274\n",
      " New best model saved at epoch 10 with val_loss: 0.002215\n",
      "Epoch 10/100, Train Loss: 0.002306, Val Loss: 0.002215, Best Val Loss: 0.002215\n",
      " New best model saved at epoch 11 with val_loss: 0.002153\n",
      " New best model saved at epoch 12 with val_loss: 0.002111\n",
      " New best model saved at epoch 13 with val_loss: 0.002063\n",
      " New best model saved at epoch 14 with val_loss: 0.002044\n",
      " New best model saved at epoch 15 with val_loss: 0.002025\n",
      "Epoch 15/100, Train Loss: 0.002085, Val Loss: 0.002025, Best Val Loss: 0.002025\n",
      " New best model saved at epoch 16 with val_loss: 0.002017\n",
      " New best model saved at epoch 17 with val_loss: 0.002005\n",
      " New best model saved at epoch 18 with val_loss: 0.001992\n",
      " New best model saved at epoch 19 with val_loss: 0.001987\n",
      " New best model saved at epoch 20 with val_loss: 0.001979\n",
      "Epoch 20/100, Train Loss: 0.002018, Val Loss: 0.001979, Best Val Loss: 0.001979\n",
      " New best model saved at epoch 21 with val_loss: 0.001974\n",
      " New best model saved at epoch 22 with val_loss: 0.001959\n",
      " New best model saved at epoch 23 with val_loss: 0.001951\n",
      " New best model saved at epoch 24 with val_loss: 0.001939\n",
      " New best model saved at epoch 25 with val_loss: 0.001931\n",
      "Epoch 25/100, Train Loss: 0.001965, Val Loss: 0.001931, Best Val Loss: 0.001931\n",
      " New best model saved at epoch 26 with val_loss: 0.001912\n",
      " New best model saved at epoch 27 with val_loss: 0.001894\n",
      " New best model saved at epoch 28 with val_loss: 0.001875\n",
      " New best model saved at epoch 29 with val_loss: 0.001862\n",
      " New best model saved at epoch 30 with val_loss: 0.001841\n",
      "Epoch 30/100, Train Loss: 0.001889, Val Loss: 0.001841, Best Val Loss: 0.001841\n",
      " New best model saved at epoch 31 with val_loss: 0.001824\n",
      " New best model saved at epoch 32 with val_loss: 0.001811\n",
      " New best model saved at epoch 33 with val_loss: 0.001796\n",
      " New best model saved at epoch 34 with val_loss: 0.001779\n",
      " New best model saved at epoch 35 with val_loss: 0.001767\n",
      "Epoch 35/100, Train Loss: 0.001813, Val Loss: 0.001767, Best Val Loss: 0.001767\n",
      " New best model saved at epoch 36 with val_loss: 0.001759\n",
      " New best model saved at epoch 37 with val_loss: 0.001746\n",
      " New best model saved at epoch 38 with val_loss: 0.001736\n",
      " New best model saved at epoch 39 with val_loss: 0.001728\n",
      " New best model saved at epoch 40 with val_loss: 0.001716\n",
      "Epoch 40/100, Train Loss: 0.001760, Val Loss: 0.001716, Best Val Loss: 0.001716\n",
      " New best model saved at epoch 41 with val_loss: 0.001706\n",
      " New best model saved at epoch 42 with val_loss: 0.001695\n",
      " New best model saved at epoch 43 with val_loss: 0.001686\n",
      " New best model saved at epoch 44 with val_loss: 0.001678\n",
      " New best model saved at epoch 45 with val_loss: 0.001666\n",
      "Epoch 45/100, Train Loss: 0.001712, Val Loss: 0.001666, Best Val Loss: 0.001666\n",
      " New best model saved at epoch 46 with val_loss: 0.001658\n",
      " New best model saved at epoch 47 with val_loss: 0.001649\n",
      " New best model saved at epoch 48 with val_loss: 0.001639\n",
      " New best model saved at epoch 49 with val_loss: 0.001629\n",
      " New best model saved at epoch 50 with val_loss: 0.001619\n",
      "Epoch 50/100, Train Loss: 0.001665, Val Loss: 0.001619, Best Val Loss: 0.001619\n",
      " New best model saved at epoch 51 with val_loss: 0.001607\n",
      " New best model saved at epoch 52 with val_loss: 0.001596\n",
      " New best model saved at epoch 53 with val_loss: 0.001584\n",
      " New best model saved at epoch 54 with val_loss: 0.001571\n",
      " New best model saved at epoch 55 with val_loss: 0.001558\n",
      "Epoch 55/100, Train Loss: 0.001611, Val Loss: 0.001558, Best Val Loss: 0.001558\n",
      " New best model saved at epoch 56 with val_loss: 0.001542\n",
      " New best model saved at epoch 57 with val_loss: 0.001527\n",
      " New best model saved at epoch 58 with val_loss: 0.001514\n",
      " New best model saved at epoch 59 with val_loss: 0.001498\n",
      " New best model saved at epoch 60 with val_loss: 0.001489\n",
      "Epoch 60/100, Train Loss: 0.001546, Val Loss: 0.001489, Best Val Loss: 0.001489\n",
      " New best model saved at epoch 61 with val_loss: 0.001477\n",
      " New best model saved at epoch 62 with val_loss: 0.001476\n",
      " New best model saved at epoch 63 with val_loss: 0.001451\n",
      " New best model saved at epoch 64 with val_loss: 0.001437\n",
      " New best model saved at epoch 65 with val_loss: 0.001431\n",
      "Epoch 65/100, Train Loss: 0.001488, Val Loss: 0.001431, Best Val Loss: 0.001431\n",
      " New best model saved at epoch 66 with val_loss: 0.001411\n",
      " New best model saved at epoch 67 with val_loss: 0.001401\n",
      " New best model saved at epoch 68 with val_loss: 0.001392\n",
      " New best model saved at epoch 69 with val_loss: 0.001378\n",
      " New best model saved at epoch 70 with val_loss: 0.001365\n",
      "Epoch 70/100, Train Loss: 0.001431, Val Loss: 0.001365, Best Val Loss: 0.001365\n",
      " New best model saved at epoch 71 with val_loss: 0.001355\n",
      " New best model saved at epoch 72 with val_loss: 0.001343\n",
      " New best model saved at epoch 73 with val_loss: 0.001331\n",
      " New best model saved at epoch 74 with val_loss: 0.001319\n",
      " New best model saved at epoch 75 with val_loss: 0.001306\n",
      "Epoch 75/100, Train Loss: 0.001375, Val Loss: 0.001306, Best Val Loss: 0.001306\n",
      " New best model saved at epoch 76 with val_loss: 0.001292\n",
      " New best model saved at epoch 77 with val_loss: 0.001282\n",
      " New best model saved at epoch 78 with val_loss: 0.001270\n",
      " New best model saved at epoch 79 with val_loss: 0.001257\n",
      " New best model saved at epoch 80 with val_loss: 0.001245\n",
      "Epoch 80/100, Train Loss: 0.001320, Val Loss: 0.001245, Best Val Loss: 0.001245\n",
      " New best model saved at epoch 81 with val_loss: 0.001234\n",
      " New best model saved at epoch 82 with val_loss: 0.001222\n",
      " New best model saved at epoch 83 with val_loss: 0.001209\n",
      " New best model saved at epoch 84 with val_loss: 0.001199\n",
      " New best model saved at epoch 85 with val_loss: 0.001186\n",
      "Epoch 85/100, Train Loss: 0.001264, Val Loss: 0.001186, Best Val Loss: 0.001186\n",
      " New best model saved at epoch 86 with val_loss: 0.001173\n",
      " New best model saved at epoch 87 with val_loss: 0.001161\n",
      " New best model saved at epoch 88 with val_loss: 0.001149\n",
      " New best model saved at epoch 89 with val_loss: 0.001135\n",
      " New best model saved at epoch 90 with val_loss: 0.001123\n",
      "Epoch 90/100, Train Loss: 0.001207, Val Loss: 0.001123, Best Val Loss: 0.001123\n",
      " New best model saved at epoch 91 with val_loss: 0.001110\n",
      " New best model saved at epoch 92 with val_loss: 0.001097\n",
      " New best model saved at epoch 93 with val_loss: 0.001084\n",
      " New best model saved at epoch 94 with val_loss: 0.001069\n",
      " New best model saved at epoch 95 with val_loss: 0.001058\n",
      "Epoch 95/100, Train Loss: 0.001149, Val Loss: 0.001058, Best Val Loss: 0.001058\n",
      " New best model saved at epoch 96 with val_loss: 0.001045\n",
      " New best model saved at epoch 97 with val_loss: 0.001031\n",
      " New best model saved at epoch 98 with val_loss: 0.001018\n",
      " New best model saved at epoch 99 with val_loss: 0.001009\n",
      " New best model saved at epoch 100 with val_loss: 0.000992\n",
      "Epoch 100/100, Train Loss: 0.001092, Val Loss: 0.000992, Best Val Loss: 0.000992\n",
      " Training completed. Best validation loss: 0.000992\n",
      "Data split: 31456 training samples, 7864 validation samples\n",
      "Training autoencoder for 100 epochs...\n",
      " New best model saved at epoch 1 with val_loss: 0.266012\n",
      "Epoch 1/100, Train Loss: 0.275175, Val Loss: 0.266012, Best Val Loss: 0.266012\n",
      " New best model saved at epoch 2 with val_loss: 0.231602\n",
      " New best model saved at epoch 3 with val_loss: 0.209323\n",
      " New best model saved at epoch 4 with val_loss: 0.176235\n",
      "Epoch 5/100, Train Loss: 0.179286, Val Loss: 0.189964, Best Val Loss: 0.176235\n",
      " New best model saved at epoch 7 with val_loss: 0.160330\n",
      " New best model saved at epoch 8 with val_loss: 0.148675\n",
      " New best model saved at epoch 9 with val_loss: 0.144249\n",
      " New best model saved at epoch 10 with val_loss: 0.126256\n",
      "Epoch 10/100, Train Loss: 0.157521, Val Loss: 0.126256, Best Val Loss: 0.126256\n",
      " New best model saved at epoch 13 with val_loss: 0.123542\n",
      " New best model saved at epoch 14 with val_loss: 0.120094\n",
      "Epoch 15/100, Train Loss: 0.126605, Val Loss: 0.121442, Best Val Loss: 0.120094\n",
      " New best model saved at epoch 16 with val_loss: 0.117379\n",
      " New best model saved at epoch 17 with val_loss: 0.117256\n",
      " New best model saved at epoch 19 with val_loss: 0.116667\n",
      " New best model saved at epoch 20 with val_loss: 0.112629\n",
      "Epoch 20/100, Train Loss: 0.119931, Val Loss: 0.112629, Best Val Loss: 0.112629\n",
      " New best model saved at epoch 21 with val_loss: 0.111972\n",
      " New best model saved at epoch 22 with val_loss: 0.110669\n",
      " New best model saved at epoch 23 with val_loss: 0.108901\n",
      " New best model saved at epoch 25 with val_loss: 0.107390\n",
      "Epoch 25/100, Train Loss: 0.112775, Val Loss: 0.107390, Best Val Loss: 0.107390\n",
      " New best model saved at epoch 26 with val_loss: 0.102650\n",
      " New best model saved at epoch 27 with val_loss: 0.099708\n",
      " New best model saved at epoch 28 with val_loss: 0.096550\n",
      " New best model saved at epoch 29 with val_loss: 0.095250\n",
      " New best model saved at epoch 30 with val_loss: 0.094048\n",
      "Epoch 30/100, Train Loss: 0.099753, Val Loss: 0.094048, Best Val Loss: 0.094048\n",
      " New best model saved at epoch 31 with val_loss: 0.090638\n",
      " New best model saved at epoch 32 with val_loss: 0.088993\n",
      " New best model saved at epoch 33 with val_loss: 0.088525\n",
      " New best model saved at epoch 35 with val_loss: 0.087120\n",
      "Epoch 35/100, Train Loss: 0.092856, Val Loss: 0.087120, Best Val Loss: 0.087120\n",
      " New best model saved at epoch 36 with val_loss: 0.085487\n",
      " New best model saved at epoch 37 with val_loss: 0.084338\n",
      " New best model saved at epoch 38 with val_loss: 0.083741\n",
      " New best model saved at epoch 39 with val_loss: 0.083479\n",
      " New best model saved at epoch 40 with val_loss: 0.082968\n",
      "Epoch 40/100, Train Loss: 0.087876, Val Loss: 0.082968, Best Val Loss: 0.082968\n",
      " New best model saved at epoch 41 with val_loss: 0.082396\n",
      " New best model saved at epoch 42 with val_loss: 0.081835\n",
      " New best model saved at epoch 43 with val_loss: 0.081462\n",
      " New best model saved at epoch 44 with val_loss: 0.081010\n",
      " New best model saved at epoch 45 with val_loss: 0.080415\n",
      "Epoch 45/100, Train Loss: 0.085425, Val Loss: 0.080415, Best Val Loss: 0.080415\n",
      " New best model saved at epoch 46 with val_loss: 0.080226\n",
      " New best model saved at epoch 47 with val_loss: 0.080190\n",
      " New best model saved at epoch 48 with val_loss: 0.079823\n",
      " New best model saved at epoch 49 with val_loss: 0.079555\n",
      " New best model saved at epoch 50 with val_loss: 0.079391\n",
      "Epoch 50/100, Train Loss: 0.083796, Val Loss: 0.079391, Best Val Loss: 0.079391\n",
      " New best model saved at epoch 51 with val_loss: 0.079121\n",
      " New best model saved at epoch 52 with val_loss: 0.078928\n",
      " New best model saved at epoch 54 with val_loss: 0.078828\n",
      " New best model saved at epoch 55 with val_loss: 0.078482\n",
      "Epoch 55/100, Train Loss: 0.082711, Val Loss: 0.078482, Best Val Loss: 0.078482\n",
      " New best model saved at epoch 56 with val_loss: 0.078415\n",
      " New best model saved at epoch 58 with val_loss: 0.078339\n",
      " New best model saved at epoch 59 with val_loss: 0.078102\n",
      " New best model saved at epoch 60 with val_loss: 0.078058\n",
      "Epoch 60/100, Train Loss: 0.081940, Val Loss: 0.078058, Best Val Loss: 0.078058\n",
      " New best model saved at epoch 62 with val_loss: 0.077847\n",
      " New best model saved at epoch 63 with val_loss: 0.077705\n",
      " New best model saved at epoch 64 with val_loss: 0.077703\n",
      " New best model saved at epoch 65 with val_loss: 0.077665\n",
      "Epoch 65/100, Train Loss: 0.081225, Val Loss: 0.077665, Best Val Loss: 0.077665\n",
      " New best model saved at epoch 66 with val_loss: 0.077494\n",
      " New best model saved at epoch 67 with val_loss: 0.077373\n",
      " New best model saved at epoch 68 with val_loss: 0.077314\n",
      " New best model saved at epoch 69 with val_loss: 0.077237\n",
      " New best model saved at epoch 70 with val_loss: 0.077113\n",
      "Epoch 70/100, Train Loss: 0.080624, Val Loss: 0.077113, Best Val Loss: 0.077113\n",
      " New best model saved at epoch 71 with val_loss: 0.077025\n",
      " New best model saved at epoch 72 with val_loss: 0.076911\n",
      " New best model saved at epoch 73 with val_loss: 0.076775\n",
      " New best model saved at epoch 74 with val_loss: 0.076616\n",
      " New best model saved at epoch 75 with val_loss: 0.076466\n",
      "Epoch 75/100, Train Loss: 0.079902, Val Loss: 0.076466, Best Val Loss: 0.076466\n",
      " New best model saved at epoch 76 with val_loss: 0.076298\n",
      " New best model saved at epoch 77 with val_loss: 0.076002\n",
      " New best model saved at epoch 78 with val_loss: 0.075731\n",
      " New best model saved at epoch 79 with val_loss: 0.075354\n",
      " New best model saved at epoch 80 with val_loss: 0.074817\n",
      "Epoch 80/100, Train Loss: 0.078619, Val Loss: 0.074817, Best Val Loss: 0.074817\n",
      " New best model saved at epoch 81 with val_loss: 0.074236\n",
      " New best model saved at epoch 82 with val_loss: 0.073200\n",
      " New best model saved at epoch 83 with val_loss: 0.072535\n",
      " New best model saved at epoch 84 with val_loss: 0.071166\n",
      "Epoch 85/100, Train Loss: 0.075270, Val Loss: 0.071600, Best Val Loss: 0.071166\n",
      " New best model saved at epoch 86 with val_loss: 0.069821\n",
      " New best model saved at epoch 88 with val_loss: 0.069080\n",
      " New best model saved at epoch 89 with val_loss: 0.068166\n",
      "Epoch 90/100, Train Loss: 0.072602, Val Loss: 0.068491, Best Val Loss: 0.068166\n",
      " New best model saved at epoch 91 with val_loss: 0.067626\n",
      " New best model saved at epoch 92 with val_loss: 0.066718\n",
      " New best model saved at epoch 94 with val_loss: 0.066356\n",
      " New best model saved at epoch 95 with val_loss: 0.065668\n",
      "Epoch 95/100, Train Loss: 0.070180, Val Loss: 0.065668, Best Val Loss: 0.065668\n",
      " New best model saved at epoch 96 with val_loss: 0.065604\n",
      " New best model saved at epoch 97 with val_loss: 0.065104\n",
      " New best model saved at epoch 98 with val_loss: 0.064393\n",
      " New best model saved at epoch 99 with val_loss: 0.063975\n",
      " New best model saved at epoch 100 with val_loss: 0.063211\n",
      "Epoch 100/100, Train Loss: 0.067901, Val Loss: 0.063211, Best Val Loss: 0.063211\n",
      " Training completed. Best validation loss: 0.063211\n",
      "Testing model with use_bpr=bpr and fusion_method=concat\n",
      "Using concatenation fusion method\n",
      "User feature layer input dim: 1158\n",
      "Course feature layer input dim: 960\n",
      "Training multimodal model for 30 epochs...\n",
      "No validation dataset provided - using training loss for model selection\n",
      "Early stopping: patience=5, delta=1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcsanguino10/local_citation_model/recommender-fusion-recsys/notebooks/multimodal_training.py:176: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'user': torch.tensor(user_feat, dtype=torch.float),\n",
      "/home/jcsanguino10/local_citation_model/recommender-fusion-recsys/notebooks/multimodal_training.py:177: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'course_positive': torch.tensor(pos_course_feat, dtype=torch.float),\n",
      "/home/jcsanguino10/local_citation_model/recommender-fusion-recsys/notebooks/multimodal_training.py:178: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'course_negative': torch.tensor(neg_course_feat, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New best model saved at epoch 1 with val_loss: 0.433889\n",
      "Epoch 1/30, Train Loss: 0.433889, Best Loss: 0.433889\n",
      " New best model saved at epoch 2 with val_loss: 0.425346\n",
      "Epoch 2/30, Train Loss: 0.425346, Best Loss: 0.425346\n",
      " New best model saved at epoch 3 with val_loss: 0.402032\n",
      "Epoch 3/30, Train Loss: 0.402032, Best Loss: 0.402032\n",
      " New best model saved at epoch 4 with val_loss: 0.398823\n",
      "Epoch 4/30, Train Loss: 0.398823, Best Loss: 0.398823\n",
      " New best model saved at epoch 5 with val_loss: 0.390082\n",
      "Epoch 5/30, Train Loss: 0.390082, Best Loss: 0.390082\n",
      " New best model saved at epoch 6 with val_loss: 0.385868\n",
      "Epoch 6/30, Train Loss: 0.385868, Best Loss: 0.385868\n",
      " New best model saved at epoch 7 with val_loss: 0.384647\n",
      "Epoch 7/30, Train Loss: 0.384647, Best Loss: 0.384647\n",
      " No improvement for 1/5 epochs\n",
      "Epoch 8/30, Train Loss: 0.410539, Best Loss: 0.384647\n",
      " No improvement for 2/5 epochs\n",
      "Epoch 9/30, Train Loss: 0.403418, Best Loss: 0.384647\n",
      " No improvement for 3/5 epochs\n",
      "Epoch 10/30, Train Loss: 0.393453, Best Loss: 0.384647\n",
      " No improvement for 4/5 epochs\n",
      "Epoch 11/30, Train Loss: 0.392101, Best Loss: 0.384647\n",
      " New best model saved at epoch 12 with val_loss: 0.384544\n",
      "Epoch 12/30, Train Loss: 0.384544, Best Loss: 0.384544\n",
      " New best model saved at epoch 13 with val_loss: 0.383591\n",
      "Epoch 13/30, Train Loss: 0.383591, Best Loss: 0.383591\n",
      " New best model saved at epoch 14 with val_loss: 0.381796\n",
      "Epoch 14/30, Train Loss: 0.381796, Best Loss: 0.381796\n",
      " New best model saved at epoch 15 with val_loss: 0.380591\n",
      "Epoch 15/30, Train Loss: 0.380591, Best Loss: 0.380591\n",
      " No improvement for 1/5 epochs\n",
      "Epoch 16/30, Train Loss: 0.383718, Best Loss: 0.380591\n",
      " No improvement for 2/5 epochs\n",
      "Epoch 17/30, Train Loss: 0.382217, Best Loss: 0.380591\n",
      " No improvement for 3/5 epochs\n",
      "Epoch 18/30, Train Loss: 0.384169, Best Loss: 0.380591\n",
      " No improvement for 4/5 epochs\n",
      "Epoch 19/30, Train Loss: 0.385624, Best Loss: 0.380591\n",
      " No improvement for 5/5 epochs\n",
      " Early stopping triggered after 20 epochs (patience: 5)\n",
      " Training completed (early stopped at epoch 20/30). Best training loss: 0.380591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating recommendations: 100%|██████████| 108/108 [00:00<00:00, 186.18it/s]\n",
      "/home/jcsanguino10/local_citation_model/recommender-fusion-recsys/notebooks/multimodal_training.py:176: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'user': torch.tensor(user_feat, dtype=torch.float),\n",
      "/home/jcsanguino10/local_citation_model/recommender-fusion-recsys/notebooks/multimodal_training.py:177: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'course_positive': torch.tensor(pos_course_feat, dtype=torch.float),\n",
      "/home/jcsanguino10/local_citation_model/recommender-fusion-recsys/notebooks/multimodal_training.py:178: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'course_negative': torch.tensor(neg_course_feat, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model with use_bpr=bpr and fusion_method=by_autoencoder\n",
      "Using autoencoder fusion method with encoding dimension 512\n",
      "User feature layer input dim: 512\n",
      "Course feature layer input dim: 512\n",
      "Training multimodal model for 30 epochs...\n",
      "No validation dataset provided - using training loss for model selection\n",
      "Early stopping: patience=5, delta=1e-05\n",
      " New best model saved at epoch 1 with val_loss: 0.412779\n",
      "Epoch 1/30, Train Loss: 0.412779, Best Loss: 0.412779\n",
      " New best model saved at epoch 2 with val_loss: 0.401568\n",
      "Epoch 2/30, Train Loss: 0.401568, Best Loss: 0.401568\n",
      " New best model saved at epoch 3 with val_loss: 0.398568\n",
      "Epoch 3/30, Train Loss: 0.398568, Best Loss: 0.398568\n",
      " New best model saved at epoch 4 with val_loss: 0.397807\n",
      "Epoch 4/30, Train Loss: 0.397807, Best Loss: 0.397807\n",
      " New best model saved at epoch 5 with val_loss: 0.397472\n",
      "Epoch 5/30, Train Loss: 0.397472, Best Loss: 0.397472\n",
      " New best model saved at epoch 6 with val_loss: 0.396784\n",
      "Epoch 6/30, Train Loss: 0.396784, Best Loss: 0.396784\n",
      " New best model saved at epoch 7 with val_loss: 0.395942\n",
      "Epoch 7/30, Train Loss: 0.395942, Best Loss: 0.395942\n",
      " No improvement for 1/5 epochs\n",
      "Epoch 8/30, Train Loss: 0.396115, Best Loss: 0.395942\n",
      " New best model saved at epoch 9 with val_loss: 0.395379\n",
      "Epoch 9/30, Train Loss: 0.395379, Best Loss: 0.395379\n",
      " No improvement for 1/5 epochs\n",
      "Epoch 10/30, Train Loss: 0.395574, Best Loss: 0.395379\n",
      " New best model saved at epoch 11 with val_loss: 0.394421\n",
      "Epoch 11/30, Train Loss: 0.394421, Best Loss: 0.394421\n",
      " New best model saved at epoch 12 with val_loss: 0.394136\n",
      "Epoch 12/30, Train Loss: 0.394136, Best Loss: 0.394136\n",
      " New best model saved at epoch 13 with val_loss: 0.394085\n",
      "Epoch 13/30, Train Loss: 0.394085, Best Loss: 0.394085\n",
      " New best model saved at epoch 14 with val_loss: 0.393154\n",
      "Epoch 14/30, Train Loss: 0.393154, Best Loss: 0.393154\n",
      " No improvement for 1/5 epochs\n",
      "Epoch 15/30, Train Loss: 0.393728, Best Loss: 0.393154\n",
      " New best model saved at epoch 16 with val_loss: 0.393040\n",
      "Epoch 16/30, Train Loss: 0.393040, Best Loss: 0.393040\n",
      " New best model saved at epoch 17 with val_loss: 0.392313\n",
      "Epoch 17/30, Train Loss: 0.392313, Best Loss: 0.392313\n",
      " New best model saved at epoch 18 with val_loss: 0.391752\n",
      "Epoch 18/30, Train Loss: 0.391752, Best Loss: 0.391752\n",
      " New best model saved at epoch 19 with val_loss: 0.391233\n",
      "Epoch 19/30, Train Loss: 0.391233, Best Loss: 0.391233\n",
      " New best model saved at epoch 20 with val_loss: 0.391051\n",
      "Epoch 20/30, Train Loss: 0.391051, Best Loss: 0.391051\n",
      " New best model saved at epoch 21 with val_loss: 0.390796\n",
      "Epoch 21/30, Train Loss: 0.390796, Best Loss: 0.390796\n",
      " New best model saved at epoch 22 with val_loss: 0.389948\n",
      "Epoch 22/30, Train Loss: 0.389948, Best Loss: 0.389948\n",
      " No improvement for 1/5 epochs\n",
      "Epoch 23/30, Train Loss: 0.389940, Best Loss: 0.389948\n",
      " New best model saved at epoch 24 with val_loss: 0.389281\n",
      "Epoch 24/30, Train Loss: 0.389281, Best Loss: 0.389281\n",
      " No improvement for 1/5 epochs\n",
      "Epoch 25/30, Train Loss: 0.389813, Best Loss: 0.389281\n",
      " New best model saved at epoch 26 with val_loss: 0.388635\n",
      "Epoch 26/30, Train Loss: 0.388635, Best Loss: 0.388635\n",
      " New best model saved at epoch 27 with val_loss: 0.387942\n",
      "Epoch 27/30, Train Loss: 0.387942, Best Loss: 0.387942\n",
      " New best model saved at epoch 28 with val_loss: 0.387671\n",
      "Epoch 28/30, Train Loss: 0.387671, Best Loss: 0.387671\n",
      " New best model saved at epoch 29 with val_loss: 0.386146\n",
      "Epoch 29/30, Train Loss: 0.386146, Best Loss: 0.386146\n",
      " New best model saved at epoch 30 with val_loss: 0.383548\n",
      "Epoch 30/30, Train Loss: 0.383548, Best Loss: 0.383548\n",
      " Training completed (full 30 epochs). Best training loss: 0.383548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating recommendations: 100%|██████████| 108/108 [00:00<00:00, 200.95it/s]\n",
      "/home/jcsanguino10/local_citation_model/recommender-fusion-recsys/notebooks/multimodal_training.py:193: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'user': torch.tensor(user_feat, dtype=torch.float),\n",
      "/home/jcsanguino10/local_citation_model/recommender-fusion-recsys/notebooks/multimodal_training.py:194: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'course_positive': torch.tensor(course_feat, dtype=torch.float),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model with use_bpr=binary and fusion_method=concat\n",
      "Using concatenation fusion method\n",
      "User feature layer input dim: 1158\n",
      "Course feature layer input dim: 960\n",
      "Training multimodal model for 30 epochs...\n",
      "No validation dataset provided - using training loss for model selection\n",
      "Early stopping: patience=5, delta=1e-05\n",
      " New best model saved at epoch 1 with val_loss: 0.513213\n",
      "Epoch 1/30, Train Loss: 0.513213, Best Loss: 0.513213\n",
      " New best model saved at epoch 2 with val_loss: 0.436436\n",
      "Epoch 2/30, Train Loss: 0.436436, Best Loss: 0.436436\n",
      " New best model saved at epoch 3 with val_loss: 0.386296\n",
      "Epoch 3/30, Train Loss: 0.386296, Best Loss: 0.386296\n",
      " New best model saved at epoch 4 with val_loss: 0.373802\n",
      "Epoch 4/30, Train Loss: 0.373802, Best Loss: 0.373802\n",
      " New best model saved at epoch 5 with val_loss: 0.365555\n",
      "Epoch 5/30, Train Loss: 0.365555, Best Loss: 0.365555\n",
      " New best model saved at epoch 6 with val_loss: 0.362465\n",
      "Epoch 6/30, Train Loss: 0.362465, Best Loss: 0.362465\n",
      " New best model saved at epoch 7 with val_loss: 0.356139\n",
      "Epoch 7/30, Train Loss: 0.356139, Best Loss: 0.356139\n",
      " New best model saved at epoch 8 with val_loss: 0.356062\n",
      "Epoch 8/30, Train Loss: 0.356062, Best Loss: 0.356062\n",
      " New best model saved at epoch 9 with val_loss: 0.351561\n",
      "Epoch 9/30, Train Loss: 0.351561, Best Loss: 0.351561\n",
      " New best model saved at epoch 10 with val_loss: 0.349461\n",
      "Epoch 10/30, Train Loss: 0.349461, Best Loss: 0.349461\n",
      " New best model saved at epoch 11 with val_loss: 0.347441\n",
      "Epoch 11/30, Train Loss: 0.347441, Best Loss: 0.347441\n",
      " New best model saved at epoch 12 with val_loss: 0.343785\n",
      "Epoch 12/30, Train Loss: 0.343785, Best Loss: 0.343785\n",
      " New best model saved at epoch 13 with val_loss: 0.342308\n",
      "Epoch 13/30, Train Loss: 0.342308, Best Loss: 0.342308\n",
      " New best model saved at epoch 14 with val_loss: 0.339353\n",
      "Epoch 14/30, Train Loss: 0.339353, Best Loss: 0.339353\n",
      " New best model saved at epoch 15 with val_loss: 0.338389\n",
      "Epoch 15/30, Train Loss: 0.338389, Best Loss: 0.338389\n",
      " New best model saved at epoch 16 with val_loss: 0.337372\n",
      "Epoch 16/30, Train Loss: 0.337372, Best Loss: 0.337372\n",
      " No improvement for 1/5 epochs\n",
      "Epoch 17/30, Train Loss: 0.337811, Best Loss: 0.337372\n",
      " New best model saved at epoch 18 with val_loss: 0.332009\n",
      "Epoch 18/30, Train Loss: 0.332009, Best Loss: 0.332009\n",
      " No improvement for 1/5 epochs\n",
      "Epoch 19/30, Train Loss: 0.332227, Best Loss: 0.332009\n",
      " No improvement for 2/5 epochs\n",
      "Epoch 20/30, Train Loss: 0.332391, Best Loss: 0.332009\n",
      " New best model saved at epoch 21 with val_loss: 0.328225\n",
      "Epoch 21/30, Train Loss: 0.328225, Best Loss: 0.328225\n",
      " No improvement for 1/5 epochs\n",
      "Epoch 22/30, Train Loss: 0.329761, Best Loss: 0.328225\n",
      " No improvement for 2/5 epochs\n",
      "Epoch 23/30, Train Loss: 0.329232, Best Loss: 0.328225\n",
      " New best model saved at epoch 24 with val_loss: 0.327975\n",
      "Epoch 24/30, Train Loss: 0.327975, Best Loss: 0.327975\n",
      " New best model saved at epoch 25 with val_loss: 0.327132\n",
      "Epoch 25/30, Train Loss: 0.327132, Best Loss: 0.327132\n",
      " No improvement for 1/5 epochs\n",
      "Epoch 26/30, Train Loss: 0.334766, Best Loss: 0.327132\n",
      " No improvement for 2/5 epochs\n",
      "Epoch 27/30, Train Loss: 0.336066, Best Loss: 0.327132\n",
      " No improvement for 3/5 epochs\n",
      "Epoch 28/30, Train Loss: 0.331283, Best Loss: 0.327132\n",
      " New best model saved at epoch 29 with val_loss: 0.317381\n",
      "Epoch 29/30, Train Loss: 0.317381, Best Loss: 0.317381\n",
      " New best model saved at epoch 30 with val_loss: 0.314419\n",
      "Epoch 30/30, Train Loss: 0.314419, Best Loss: 0.314419\n",
      " Training completed (full 30 epochs). Best training loss: 0.314419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating recommendations: 100%|██████████| 108/108 [00:08<00:00, 13.41it/s]\n",
      "/home/jcsanguino10/local_citation_model/recommender-fusion-recsys/notebooks/multimodal_training.py:193: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'user': torch.tensor(user_feat, dtype=torch.float),\n",
      "/home/jcsanguino10/local_citation_model/recommender-fusion-recsys/notebooks/multimodal_training.py:194: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'course_positive': torch.tensor(course_feat, dtype=torch.float),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model with use_bpr=binary and fusion_method=concat\n",
      "Using concatenation fusion method\n",
      "User feature layer input dim: 1158\n",
      "Course feature layer input dim: 960\n",
      "Training multimodal model for 30 epochs...\n",
      "No validation dataset provided - using training loss for model selection\n",
      "Early stopping: patience=5, delta=1e-05\n",
      " New best model saved at epoch 1 with val_loss: 0.494504\n",
      "Epoch 1/30, Train Loss: 0.494504, Best Loss: 0.494504\n",
      " New best model saved at epoch 2 with val_loss: 0.469898\n",
      "Epoch 2/30, Train Loss: 0.469898, Best Loss: 0.469898\n",
      " New best model saved at epoch 3 with val_loss: 0.464900\n",
      "Epoch 3/30, Train Loss: 0.464900, Best Loss: 0.464900\n",
      " New best model saved at epoch 4 with val_loss: 0.462170\n",
      "Epoch 4/30, Train Loss: 0.462170, Best Loss: 0.462170\n",
      " New best model saved at epoch 5 with val_loss: 0.460625\n",
      "Epoch 5/30, Train Loss: 0.460625, Best Loss: 0.460625\n",
      " New best model saved at epoch 6 with val_loss: 0.458120\n",
      "Epoch 6/30, Train Loss: 0.458120, Best Loss: 0.458120\n",
      " New best model saved at epoch 7 with val_loss: 0.457766\n",
      "Epoch 7/30, Train Loss: 0.457766, Best Loss: 0.457766\n",
      " No improvement for 1/5 epochs\n",
      "Epoch 8/30, Train Loss: 0.458446, Best Loss: 0.457766\n",
      " No improvement for 2/5 epochs\n",
      "Epoch 9/30, Train Loss: 0.457972, Best Loss: 0.457766\n",
      " New best model saved at epoch 10 with val_loss: 0.457699\n",
      "Epoch 10/30, Train Loss: 0.457699, Best Loss: 0.457699\n",
      " New best model saved at epoch 11 with val_loss: 0.456046\n",
      "Epoch 11/30, Train Loss: 0.456046, Best Loss: 0.456046\n",
      " No improvement for 1/5 epochs\n",
      "Epoch 12/30, Train Loss: 0.457394, Best Loss: 0.456046\n",
      " No improvement for 2/5 epochs\n",
      "Epoch 13/30, Train Loss: 0.456267, Best Loss: 0.456046\n",
      " New best model saved at epoch 14 with val_loss: 0.454648\n",
      "Epoch 14/30, Train Loss: 0.454648, Best Loss: 0.454648\n",
      " No improvement for 1/5 epochs\n",
      "Epoch 15/30, Train Loss: 0.454787, Best Loss: 0.454648\n",
      " New best model saved at epoch 16 with val_loss: 0.451579\n",
      "Epoch 16/30, Train Loss: 0.451579, Best Loss: 0.451579\n",
      " New best model saved at epoch 17 with val_loss: 0.391563\n",
      "Epoch 17/30, Train Loss: 0.391563, Best Loss: 0.391563\n",
      " New best model saved at epoch 18 with val_loss: 0.373637\n",
      "Epoch 18/30, Train Loss: 0.373637, Best Loss: 0.373637\n",
      " New best model saved at epoch 19 with val_loss: 0.366032\n",
      "Epoch 19/30, Train Loss: 0.366032, Best Loss: 0.366032\n",
      " New best model saved at epoch 20 with val_loss: 0.361460\n",
      "Epoch 20/30, Train Loss: 0.361460, Best Loss: 0.361460\n",
      " New best model saved at epoch 21 with val_loss: 0.355554\n",
      "Epoch 21/30, Train Loss: 0.355554, Best Loss: 0.355554\n",
      " New best model saved at epoch 22 with val_loss: 0.351729\n",
      "Epoch 22/30, Train Loss: 0.351729, Best Loss: 0.351729\n",
      " New best model saved at epoch 23 with val_loss: 0.350142\n",
      "Epoch 23/30, Train Loss: 0.350142, Best Loss: 0.350142\n",
      " New best model saved at epoch 24 with val_loss: 0.346929\n",
      "Epoch 24/30, Train Loss: 0.346929, Best Loss: 0.346929\n",
      " New best model saved at epoch 25 with val_loss: 0.346084\n",
      "Epoch 25/30, Train Loss: 0.346084, Best Loss: 0.346084\n",
      " New best model saved at epoch 26 with val_loss: 0.342048\n",
      "Epoch 26/30, Train Loss: 0.342048, Best Loss: 0.342048\n",
      " New best model saved at epoch 27 with val_loss: 0.341552\n",
      "Epoch 27/30, Train Loss: 0.341552, Best Loss: 0.341552\n",
      " New best model saved at epoch 28 with val_loss: 0.338980\n",
      "Epoch 28/30, Train Loss: 0.338980, Best Loss: 0.338980\n",
      " New best model saved at epoch 29 with val_loss: 0.338186\n",
      "Epoch 29/30, Train Loss: 0.338186, Best Loss: 0.338186\n",
      " New best model saved at epoch 30 with val_loss: 0.336327\n",
      "Epoch 30/30, Train Loss: 0.336327, Best Loss: 0.336327\n",
      " Training completed (full 30 epochs). Best training loss: 0.336327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating recommendations: 100%|██████████| 108/108 [00:08<00:00, 13.37it/s]\n",
      "/home/jcsanguino10/local_citation_model/recommender-fusion-recsys/notebooks/multimodal_training.py:193: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'user': torch.tensor(user_feat, dtype=torch.float),\n",
      "/home/jcsanguino10/local_citation_model/recommender-fusion-recsys/notebooks/multimodal_training.py:194: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'course_positive': torch.tensor(course_feat, dtype=torch.float),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model with use_bpr=binary and fusion_method=by_autoencoder\n",
      "Using autoencoder fusion method with encoding dimension 512\n",
      "User feature layer input dim: 512\n",
      "Course feature layer input dim: 512\n",
      "Training multimodal model for 30 epochs...\n",
      "No validation dataset provided - using training loss for model selection\n",
      "Early stopping: patience=5, delta=1e-05\n",
      " New best model saved at epoch 1 with val_loss: 0.482399\n",
      "Epoch 1/30, Train Loss: 0.482399, Best Loss: 0.482399\n",
      " New best model saved at epoch 2 with val_loss: 0.458383\n",
      "Epoch 2/30, Train Loss: 0.458383, Best Loss: 0.458383\n",
      " New best model saved at epoch 3 with val_loss: 0.455846\n",
      "Epoch 3/30, Train Loss: 0.455846, Best Loss: 0.455846\n",
      " New best model saved at epoch 4 with val_loss: 0.451627\n",
      "Epoch 4/30, Train Loss: 0.451627, Best Loss: 0.451627\n",
      " New best model saved at epoch 5 with val_loss: 0.451206\n",
      "Epoch 5/30, Train Loss: 0.451206, Best Loss: 0.451206\n",
      " New best model saved at epoch 6 with val_loss: 0.449574\n",
      "Epoch 6/30, Train Loss: 0.449574, Best Loss: 0.449574\n",
      " New best model saved at epoch 7 with val_loss: 0.446887\n",
      "Epoch 7/30, Train Loss: 0.446887, Best Loss: 0.446887\n",
      " New best model saved at epoch 8 with val_loss: 0.444659\n",
      "Epoch 8/30, Train Loss: 0.444659, Best Loss: 0.444659\n",
      " New best model saved at epoch 9 with val_loss: 0.442335\n",
      "Epoch 9/30, Train Loss: 0.442335, Best Loss: 0.442335\n",
      " New best model saved at epoch 10 with val_loss: 0.439399\n",
      "Epoch 10/30, Train Loss: 0.439399, Best Loss: 0.439399\n",
      " New best model saved at epoch 11 with val_loss: 0.435175\n",
      "Epoch 11/30, Train Loss: 0.435175, Best Loss: 0.435175\n",
      " New best model saved at epoch 12 with val_loss: 0.431413\n",
      "Epoch 12/30, Train Loss: 0.431413, Best Loss: 0.431413\n",
      " New best model saved at epoch 13 with val_loss: 0.429415\n",
      "Epoch 13/30, Train Loss: 0.429415, Best Loss: 0.429415\n",
      " New best model saved at epoch 14 with val_loss: 0.427537\n",
      "Epoch 14/30, Train Loss: 0.427537, Best Loss: 0.427537\n",
      " New best model saved at epoch 15 with val_loss: 0.425436\n",
      "Epoch 15/30, Train Loss: 0.425436, Best Loss: 0.425436\n",
      " New best model saved at epoch 16 with val_loss: 0.422723\n",
      "Epoch 16/30, Train Loss: 0.422723, Best Loss: 0.422723\n",
      " New best model saved at epoch 17 with val_loss: 0.422178\n",
      "Epoch 17/30, Train Loss: 0.422178, Best Loss: 0.422178\n",
      " New best model saved at epoch 18 with val_loss: 0.419121\n",
      "Epoch 18/30, Train Loss: 0.419121, Best Loss: 0.419121\n",
      " New best model saved at epoch 19 with val_loss: 0.417586\n",
      "Epoch 19/30, Train Loss: 0.417586, Best Loss: 0.417586\n",
      " New best model saved at epoch 20 with val_loss: 0.416298\n",
      "Epoch 20/30, Train Loss: 0.416298, Best Loss: 0.416298\n",
      " New best model saved at epoch 21 with val_loss: 0.412108\n",
      "Epoch 21/30, Train Loss: 0.412108, Best Loss: 0.412108\n",
      " No improvement for 1/5 epochs\n",
      "Epoch 22/30, Train Loss: 0.413150, Best Loss: 0.412108\n",
      " New best model saved at epoch 23 with val_loss: 0.410986\n",
      "Epoch 23/30, Train Loss: 0.410986, Best Loss: 0.410986\n",
      " New best model saved at epoch 24 with val_loss: 0.406269\n",
      "Epoch 24/30, Train Loss: 0.406269, Best Loss: 0.406269\n",
      " New best model saved at epoch 25 with val_loss: 0.405506\n",
      "Epoch 25/30, Train Loss: 0.405506, Best Loss: 0.405506\n",
      " New best model saved at epoch 26 with val_loss: 0.405388\n",
      "Epoch 26/30, Train Loss: 0.405388, Best Loss: 0.405388\n",
      " New best model saved at epoch 27 with val_loss: 0.404389\n",
      "Epoch 27/30, Train Loss: 0.404389, Best Loss: 0.404389\n",
      " New best model saved at epoch 28 with val_loss: 0.401592\n",
      "Epoch 28/30, Train Loss: 0.401592, Best Loss: 0.401592\n",
      " New best model saved at epoch 29 with val_loss: 0.401410\n",
      "Epoch 29/30, Train Loss: 0.401410, Best Loss: 0.401410\n",
      " New best model saved at epoch 30 with val_loss: 0.400690\n",
      "Epoch 30/30, Train Loss: 0.400690, Best Loss: 0.400690\n",
      " Training completed (full 30 epochs). Best training loss: 0.400690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating recommendations: 100%|██████████| 108/108 [00:07<00:00, 13.86it/s]\n",
      "/home/jcsanguino10/local_citation_model/recommender-fusion-recsys/notebooks/multimodal_training.py:193: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'user': torch.tensor(user_feat, dtype=torch.float),\n",
      "/home/jcsanguino10/local_citation_model/recommender-fusion-recsys/notebooks/multimodal_training.py:194: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'course_positive': torch.tensor(course_feat, dtype=torch.float),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model with use_bpr=binary and fusion_method=by_autoencoder\n",
      "Using autoencoder fusion method with encoding dimension 512\n",
      "User feature layer input dim: 512\n",
      "Course feature layer input dim: 512\n",
      "Training multimodal model for 30 epochs...\n",
      "No validation dataset provided - using training loss for model selection\n",
      "Early stopping: patience=5, delta=1e-05\n",
      " New best model saved at epoch 1 with val_loss: 0.484073\n",
      "Epoch 1/30, Train Loss: 0.484073, Best Loss: 0.484073\n",
      " New best model saved at epoch 2 with val_loss: 0.458345\n",
      "Epoch 2/30, Train Loss: 0.458345, Best Loss: 0.458345\n",
      " New best model saved at epoch 3 with val_loss: 0.455479\n",
      "Epoch 3/30, Train Loss: 0.455479, Best Loss: 0.455479\n",
      " New best model saved at epoch 4 with val_loss: 0.450547\n",
      "Epoch 4/30, Train Loss: 0.450547, Best Loss: 0.450547\n",
      " New best model saved at epoch 5 with val_loss: 0.449052\n",
      "Epoch 5/30, Train Loss: 0.449052, Best Loss: 0.449052\n",
      " New best model saved at epoch 6 with val_loss: 0.448356\n",
      "Epoch 6/30, Train Loss: 0.448356, Best Loss: 0.448356\n",
      " New best model saved at epoch 7 with val_loss: 0.446200\n",
      "Epoch 7/30, Train Loss: 0.446200, Best Loss: 0.446200\n",
      " New best model saved at epoch 8 with val_loss: 0.441958\n",
      "Epoch 8/30, Train Loss: 0.441958, Best Loss: 0.441958\n",
      " New best model saved at epoch 9 with val_loss: 0.440443\n",
      "Epoch 9/30, Train Loss: 0.440443, Best Loss: 0.440443\n",
      " New best model saved at epoch 10 with val_loss: 0.438181\n",
      "Epoch 10/30, Train Loss: 0.438181, Best Loss: 0.438181\n",
      " New best model saved at epoch 11 with val_loss: 0.432664\n",
      "Epoch 11/30, Train Loss: 0.432664, Best Loss: 0.432664\n",
      " New best model saved at epoch 12 with val_loss: 0.430814\n",
      "Epoch 12/30, Train Loss: 0.430814, Best Loss: 0.430814\n",
      " New best model saved at epoch 13 with val_loss: 0.428959\n",
      "Epoch 13/30, Train Loss: 0.428959, Best Loss: 0.428959\n",
      " New best model saved at epoch 14 with val_loss: 0.426909\n",
      "Epoch 14/30, Train Loss: 0.426909, Best Loss: 0.426909\n",
      " New best model saved at epoch 15 with val_loss: 0.425285\n",
      "Epoch 15/30, Train Loss: 0.425285, Best Loss: 0.425285\n",
      " New best model saved at epoch 16 with val_loss: 0.421003\n",
      "Epoch 16/30, Train Loss: 0.421003, Best Loss: 0.421003\n",
      " New best model saved at epoch 17 with val_loss: 0.419441\n",
      "Epoch 17/30, Train Loss: 0.419441, Best Loss: 0.419441\n",
      " New best model saved at epoch 18 with val_loss: 0.418514\n",
      "Epoch 18/30, Train Loss: 0.418514, Best Loss: 0.418514\n",
      " New best model saved at epoch 19 with val_loss: 0.415863\n",
      "Epoch 19/30, Train Loss: 0.415863, Best Loss: 0.415863\n",
      " New best model saved at epoch 20 with val_loss: 0.413382\n",
      "Epoch 20/30, Train Loss: 0.413382, Best Loss: 0.413382\n",
      " New best model saved at epoch 21 with val_loss: 0.410913\n",
      "Epoch 21/30, Train Loss: 0.410913, Best Loss: 0.410913\n",
      " No improvement for 1/5 epochs\n",
      "Epoch 22/30, Train Loss: 0.411215, Best Loss: 0.410913\n",
      " New best model saved at epoch 23 with val_loss: 0.408336\n",
      "Epoch 23/30, Train Loss: 0.408336, Best Loss: 0.408336\n",
      " New best model saved at epoch 24 with val_loss: 0.406881\n",
      "Epoch 24/30, Train Loss: 0.406881, Best Loss: 0.406881\n",
      " New best model saved at epoch 25 with val_loss: 0.404215\n",
      "Epoch 25/30, Train Loss: 0.404215, Best Loss: 0.404215\n",
      " New best model saved at epoch 26 with val_loss: 0.404002\n",
      "Epoch 26/30, Train Loss: 0.404002, Best Loss: 0.404002\n",
      " New best model saved at epoch 27 with val_loss: 0.401810\n",
      "Epoch 27/30, Train Loss: 0.401810, Best Loss: 0.401810\n",
      " New best model saved at epoch 28 with val_loss: 0.399883\n",
      "Epoch 28/30, Train Loss: 0.399883, Best Loss: 0.399883\n",
      " New best model saved at epoch 29 with val_loss: 0.399504\n",
      "Epoch 29/30, Train Loss: 0.399504, Best Loss: 0.399504\n",
      " New best model saved at epoch 30 with val_loss: 0.396556\n",
      "Epoch 30/30, Train Loss: 0.396556, Best Loss: 0.396556\n",
      " Training completed (full 30 epochs). Best training loss: 0.396556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating recommendations: 100%|██████████| 108/108 [00:07<00:00, 13.89it/s]\n"
     ]
    }
   ],
   "source": [
    "results_df = mt.test_multimodal_model(\n",
    "    columns_to_concat_courses=['item_bpr_embedding', 'item_graph_embedding', 'item_text_embedding'],\n",
    "    columns_to_concat_users=['user_bpr_embedding', 'user_graph_embedding', 'user_text_embedding', 'user_sequence_embedding'],\n",
    "    encoding_dims=[720, 512],\n",
    "    shared_dimensions=128,\n",
    "    layers_per_modality=[256, 128],\n",
    "    regularization_bpr_values=[0.005]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3b1ce72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_path</th>\n",
       "      <th>use_bpr</th>\n",
       "      <th>fusion_method</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>avg_mrr</th>\n",
       "      <th>avg_ndcg_at_k</th>\n",
       "      <th>avg_precision_at_k</th>\n",
       "      <th>avg_custom_precision_at_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/jcsanguino10/local_citation_model/models...</td>\n",
       "      <td>bpr</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.046595</td>\n",
       "      <td>0.064016</td>\n",
       "      <td>0.023838</td>\n",
       "      <td>0.069178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/jcsanguino10/local_citation_model/models...</td>\n",
       "      <td>bpr</td>\n",
       "      <td>by_autoencoder</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.106455</td>\n",
       "      <td>0.144567</td>\n",
       "      <td>0.054670</td>\n",
       "      <td>0.160302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/jcsanguino10/local_citation_model/models...</td>\n",
       "      <td>binary</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.157383</td>\n",
       "      <td>0.211662</td>\n",
       "      <td>0.076759</td>\n",
       "      <td>0.229693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/jcsanguino10/local_citation_model/models...</td>\n",
       "      <td>binary</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.160707</td>\n",
       "      <td>0.215638</td>\n",
       "      <td>0.078217</td>\n",
       "      <td>0.233571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/jcsanguino10/local_citation_model/models...</td>\n",
       "      <td>binary</td>\n",
       "      <td>by_autoencoder</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.154318</td>\n",
       "      <td>0.211680</td>\n",
       "      <td>0.079528</td>\n",
       "      <td>0.235723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/home/jcsanguino10/local_citation_model/models...</td>\n",
       "      <td>binary</td>\n",
       "      <td>by_autoencoder</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.151039</td>\n",
       "      <td>0.210068</td>\n",
       "      <td>0.080256</td>\n",
       "      <td>0.238844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model_path use_bpr   fusion_method  \\\n",
       "0  /home/jcsanguino10/local_citation_model/models...     bpr          concat   \n",
       "1  /home/jcsanguino10/local_citation_model/models...     bpr  by_autoencoder   \n",
       "2  /home/jcsanguino10/local_citation_model/models...  binary          concat   \n",
       "3  /home/jcsanguino10/local_citation_model/models...  binary          concat   \n",
       "4  /home/jcsanguino10/local_citation_model/models...  binary  by_autoencoder   \n",
       "5  /home/jcsanguino10/local_citation_model/models...  binary  by_autoencoder   \n",
       "\n",
       "   reg_lambda   avg_mrr  avg_ndcg_at_k  avg_precision_at_k  \\\n",
       "0       0.005  0.046595       0.064016            0.023838   \n",
       "1       0.005  0.106455       0.144567            0.054670   \n",
       "2       0.000  0.157383       0.211662            0.076759   \n",
       "3       0.000  0.160707       0.215638            0.078217   \n",
       "4       0.000  0.154318       0.211680            0.079528   \n",
       "5       0.000  0.151039       0.210068            0.080256   \n",
       "\n",
       "   avg_custom_precision_at_k  \n",
       "0                   0.069178  \n",
       "1                   0.160302  \n",
       "2                   0.229693  \n",
       "3                   0.233571  \n",
       "4                   0.235723  \n",
       "5                   0.238844  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6e33d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "df_test= df_test[['user_id', 'full_item_seq']].drop_duplicates(subset=['user_id'])\n",
    "temp_df_1 = df[['user_id', 'user_bpr_embedding', 'full_item_seq']].drop_duplicates(subset=['user_id'])\n",
    "temp_df_2 = df[['item_id', 'item_bpr_embedding']].drop_duplicates(subset=['item_id'])\n",
    "\n",
    "#create a list of tuples with item_id and the corresponding embedding as a numpy array\n",
    "item_embeddings = [(row['item_id'], np.array(row['item_bpr_embedding'])) for index, row in temp_df_2.iterrows()]\n",
    "\n",
    "#create a list of tuples with user_id and the corresponding embedding as a numpy array\n",
    "user_embeddings = [(row['user_id'], np.array(row['user_bpr_embedding'])) for index, row in temp_df_1.iterrows()]\n",
    "\n",
    "#create a dictionary where for each user_id we have the item_id that have the best dot product with the user embedding\n",
    "user_recommendations = {}\n",
    "for user_id, user_emb in user_embeddings:\n",
    "    #calculate the dot product between the user embedding and all item embeddings\n",
    "    dot_products = [(item_id, np.dot(user_emb, item_emb)) for item_id, item_emb in item_embeddings]\n",
    "    #sort the dot products in descending order\n",
    "    dot_products = sorted(dot_products, key=lambda x: x[1], reverse=True)\n",
    "    #get the top 5 item ids checking that they are not in the user's full_item_seq\n",
    "    top_5_items = [item_id for item_id, _ in dot_products if item_id not in temp_df_1[temp_df_1['user_id'] == user_id]['full_item_seq'].values[0]][:5]\n",
    "    user_recommendations[user_id] = top_5_items\n",
    "\n",
    "#Save the recommendations as a new column in the dataframe\n",
    "df_test['top_5_recommendations'] = df_test['user_id'].map(user_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8809676e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>full_item_seq</th>\n",
       "      <th>top_5_recommendations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[6897]</td>\n",
       "      <td>[6876, 6871, 6870, 6895, 6875]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[6920]</td>\n",
       "      <td>[6870, 6871, 6872, 6902, 6876]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[6937, 6961, 6895, 6950, 6964, 6965, 6994, 702...</td>\n",
       "      <td>[6902, 6895, 6894, 6906, 6899]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>[6996]</td>\n",
       "      <td>[6865, 6899, 6902, 6900, 6906]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>[6901, 6865, 6912]</td>\n",
       "      <td>[6871, 6876, 6875, 6902, 6865]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11915</th>\n",
       "      <td>6858</td>\n",
       "      <td>[6902, 6872]</td>\n",
       "      <td>[6872, 6902, 6870, 6871, 6906]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11917</th>\n",
       "      <td>6859</td>\n",
       "      <td>[6865, 6902]</td>\n",
       "      <td>[6865, 6902, 6899, 6906, 6893]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11919</th>\n",
       "      <td>6860</td>\n",
       "      <td>[6887]</td>\n",
       "      <td>[6920, 6887, 6958, 6864, 6985]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11920</th>\n",
       "      <td>6861</td>\n",
       "      <td>[7000, 6901, 6943]</td>\n",
       "      <td>[6870, 6899, 6871, 6906, 6896]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11923</th>\n",
       "      <td>6862</td>\n",
       "      <td>[6902]</td>\n",
       "      <td>[6865, 6902, 6906, 6870, 6899]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6863 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id                                      full_item_seq  \\\n",
       "0            0                                             [6897]   \n",
       "1            1                                             [6920]   \n",
       "2            2  [6937, 6961, 6895, 6950, 6964, 6965, 6994, 702...   \n",
       "16           3                                             [6996]   \n",
       "17           4                                 [6901, 6865, 6912]   \n",
       "...        ...                                                ...   \n",
       "11915     6858                                       [6902, 6872]   \n",
       "11917     6859                                       [6865, 6902]   \n",
       "11919     6860                                             [6887]   \n",
       "11920     6861                                 [7000, 6901, 6943]   \n",
       "11923     6862                                             [6902]   \n",
       "\n",
       "                top_5_recommendations  \n",
       "0      [6876, 6871, 6870, 6895, 6875]  \n",
       "1      [6870, 6871, 6872, 6902, 6876]  \n",
       "2      [6902, 6895, 6894, 6906, 6899]  \n",
       "16     [6865, 6899, 6902, 6900, 6906]  \n",
       "17     [6871, 6876, 6875, 6902, 6865]  \n",
       "...                               ...  \n",
       "11915  [6872, 6902, 6870, 6871, 6906]  \n",
       "11917  [6865, 6902, 6899, 6906, 6893]  \n",
       "11919  [6920, 6887, 6958, 6864, 6985]  \n",
       "11920  [6870, 6899, 6871, 6906, 6896]  \n",
       "11923  [6865, 6902, 6906, 6870, 6899]  \n",
       "\n",
       "[6863 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b74cde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/jcsanguino10/local_citation_model/Secuencial SR')\n",
    "from evaluation_metrics import calculate_average_mrr, calculate_average_precision_at_k, calculate_average_ndcg_at_k, calculate_average_custom_precision_at_k\n",
    "\n",
    "k=5\n",
    "\n",
    "courses_test_dataset = df_test[\"full_item_seq\"].to_list()\n",
    "courses_recommended_list = df_test[\"top_5_recommendations\"].to_list()\n",
    "\n",
    "avg_mrr = calculate_average_mrr(courses_test_dataset, courses_recommended_list)\n",
    "avg_ndcg_at_k = calculate_average_ndcg_at_k(courses_test_dataset, courses_recommended_list, k)\n",
    "avg_precision_at_k = calculate_average_precision_at_k(courses_test_dataset, courses_recommended_list, k)\n",
    "avg_custom_precision_at_k = calculate_average_custom_precision_at_k(courses_test_dataset, courses_recommended_list, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28bab093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.207749, NDCG@5: 0.277581, Precision@5: 0.100219, Custom Precision@5: 0.308478\n"
     ]
    }
   ],
   "source": [
    "print(f\"MRR: {avg_mrr:.6f}, NDCG@{k}: {avg_ndcg_at_k:.6f}, Precision@{k}: {avg_precision_at_k:.6f}, Custom Precision@{k}: {avg_custom_precision_at_k:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local_citation_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
